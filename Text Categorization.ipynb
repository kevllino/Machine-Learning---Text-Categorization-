{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import log\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "<a href=\"http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\">Text Analytics with Sklearn</a>\n",
    "\n",
    "<a href=\"http://arxiv.org/pdf/1410.5329v3.pdf\">Naive Bayes and text classification</a>\n",
    "\n",
    "<a href=\"http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\">Stanford NLP</a>\n",
    "\n",
    "<a href=\"http://www.folkstalk.com/2011/12/good-examples-of-awk-command-in-unix.html\">Awk 101</a>\n",
    "\n",
    "<a href=\"http://www.math.utah.edu/docs/info/gawk_5.html\">Awk tutorial for regex</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to import and structure data in a dataframe\n",
    "# we trim spaces to be able to split the word in ngrams later \n",
    "# and convert letters to lowercase\n",
    "def raw_data_to_dataframe(path):\n",
    "    text = open(path).read().split(\"\\n\")\n",
    "    intermediate_form = [text[i].split(\"\\t\") for i in range(len(text))]\n",
    "    cheese_disease_df = DataFrame()\n",
    "    cheese_disease_df[\"name\"] = [(intermediate_form[i][1].replace(\" \",\"\")).lower() for i in range(len(intermediate_form)-1)]\n",
    "    cheese_disease_df[\"class\"] = [intermediate_form[i][0] for i in range(len(intermediate_form)-1)]\n",
    "    return cheese_disease_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>backpain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dissociativedisorders</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lipoma</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bluerathgore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gallstones</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name class\n",
       "0               backpain     2\n",
       "1  dissociativedisorders     2\n",
       "2                 lipoma     2\n",
       "3           bluerathgore     1\n",
       "4             gallstones     2"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating training and testing DataFrame\n",
    "# class: 1<=>cheeseName and 2<=>diseaseName\n",
    "cheese_disease_df_train = raw_data_to_dataframe(\"cheeseDisease.train\")\n",
    "cheese_disease_df_test = raw_data_to_dataframe(\"cheeseDisease.test\")\n",
    "cheese_disease_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words model \n",
    "<b>In order to train a Machine Leanring model, we need to turn the text content into numerical feature vectors.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing our vocabulary\n",
    "We first, assign a fixed integer id to every ngram occurring in any word of the training set. \n",
    "To <b>implement the count vector by scratch, we first created a tokenizer to split every word in ngrams</b>, e.g. <br> \n",
    "\"backpain\"--tokenizer--> [ack, ain, bac, ckp, kpa, pai] for trigrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implement a trigram tokenizer\n",
    "def tokenizer(word,ngram):\n",
    "    ngrams = []\n",
    "    global_i = 0\n",
    "    j = ngram\n",
    "    while global_i < (len(word) + 1 - ngram):\n",
    "        i = global_i\n",
    "        while j < len(word) + 1:\n",
    "            ngrams.append(word[i:j])\n",
    "            i = j - 1\n",
    "            j += ngram - 1\n",
    "        global_i +=1\n",
    "        j = ngram +  global_i\n",
    "    return list(np.unique(ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenizing the names elements of the dataframe \n",
    "# to return list of ngrams in our cells\n",
    "# Apply tokenization to the entire column names\n",
    "def tokenize_names(cheese_disease_df):\n",
    "    pack = []\n",
    "    tokenized_names = [tokenizer(cheese_disease_df.ix[i,0], 3) for i in range(len(cheese_disease_df))]\n",
    "    cheese_disease_df_tokenized = cheese_disease_df\n",
    "    cheese_disease_df_tokenized[\"name\"] = tokenized_names\n",
    "    pack.append(cheese_disease_df_tokenized)\n",
    "    pack.append(tokenized_names)\n",
    "    return pack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ack, ain, bac, ckp, kpa, pai]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ati, cia, der, dis, edi, ers, iat, iso, iss, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ipo, lip, oma, pom]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ath, blu, era, gor, hgo, lue, ore, rat, thg, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[all, gal, lls, lst, nes, one, sto, ton]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name class\n",
       "0                     [ack, ain, bac, ckp, kpa, pai]     2\n",
       "1  [ati, cia, der, dis, edi, ers, iat, iso, iss, ...     2\n",
       "2                               [ipo, lip, oma, pom]     2\n",
       "3  [ath, blu, era, gor, hgo, lue, ore, rat, thg, ...     1\n",
       "4           [all, gal, lls, lst, nes, one, sto, ton]     2"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_train =  tokenize_names(cheese_disease_df_train)\n",
    "cheese_disease_df_train_tokenized = result_train[0]\n",
    "tokenized_train_names = result_train[1]\n",
    "cheese_disease_df_test_tokenized = tokenize_names(cheese_disease_df_test)[0]\n",
    "cheese_disease_df_train_tokenized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tokenizing, the process consists in <b>creating a vocabulary, i.e. a set of unique ngrams. Each ngram will be identified by an unique integer identifier</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_of_trigrams = []\n",
    "for i in range(len(tokenized_train_names)):\n",
    "    bag_of_trigrams += tokenized_train_names[i]\n",
    "unique_trigrams = np.unique(bag_of_trigrams)\n",
    "\n",
    "# create a dictionary out of the previous array \n",
    "# with the following (key, value) pairs: trigram => unique_id\n",
    "dict_unique_trigrams = dict()\n",
    "for i, value in enumerate(unique_trigrams):\n",
    "    dict_unique_trigrams.update({value:i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = len(dict_unique_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting occurences of features\n",
    "For each name, <b>we count the number of occurrences of each ngram and store them in a matrix X[i, j] with i, the number of names and j, the unique identifier for each ngram in our dictionary. </b>\n",
    "Note that our features are the unique ngrams.\n",
    "Here's a simple method to return occurences of each ngram in our corpus of words: occurences_in_corpus = Counter(bag_of_trigrams). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_count_vectorizer(cheese_disease_df_tokenized):\n",
    "    # here we compute the occurences of trigrams for each words, \n",
    "    # i.e. each cell of the column \"names\"\n",
    "    occurences_per_words = []\n",
    "    for i in range(len(cheese_disease_df_tokenized )):\n",
    "        occurences_per_words.append(dict(Counter(cheese_disease_df_tokenized .ix[i,0])))\n",
    "\n",
    "    # creating an initial matrix of size i*j (with i = number of words)\n",
    "    # and j = vector of unique ids of the trigrams in our vocabulary\n",
    "    # As a result, this matrix will be filled with a lot of 0s.\n",
    "    # Add one last column on order to store the rows class. \n",
    "    count_vectorizer = np.zeros(shape=(len(cheese_disease_df_tokenized),len(dict_unique_trigrams)+1))\n",
    "    for i in range(len(cheese_disease_df_tokenized)):\n",
    "        for j in range(len(dict_unique_trigrams)):\n",
    "            for d in occurences_per_words[i].keys(): \n",
    "                if dict_unique_trigrams.get(d) == j: \n",
    "                    count_vectorizer[i,j] = occurences_per_words[i].get(d)\n",
    "    \n",
    "    return count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating count_vectorizer for train dataframe\n",
    "count_vectorizer_train = create_count_vectorizer(cheese_disease_df_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have computed our matrix which counts the occurences for each ngram in each word, note that <b>the matrix is filled with a lot of 0 values, we call this a sparse matrix</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum-Likelihood Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under naive assumption, we have 2 assumptions: \n",
    "\n",
    "1 - <b>Samples are independent and identically distributed</b>. <b>The prior probabilities can be obtained via the maximum-likelihood estimate </b>(i.e., the frequencies of how often each class label is represented in the training dataset:\n",
    "\n",
    "$$ P_{cheese} = \\frac{numberOfCheeseNames}{overallNumberOfSamples} $$\n",
    "$$P_{disease} = \\frac{numberOfDiseaseNames}{overallNumberOfSamples} $$\n",
    "\n",
    "2 - Features are mutually independent. Hence, the class-conditional probabilities can be calculated as a product of the individual conditional probabilities\n",
    "$$ P(features|class) = \\prod_{i=1}^{n_{features}} P(features_i | class) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prior_probabilities(cheese_disease_df):\n",
    "    # we first compute prior probabilities of a ngram belonging to class cheese or disease\n",
    "    number_of_samples = len(cheese_disease_df[\"class\"])\n",
    "    number_of_cheese_names = sum(cheese_disease_df[\"class\"]=='1')\n",
    "    number_of_disease_names = sum(cheese_disease_df[\"class\"]=='2')\n",
    "    probability_cheese_name = number_of_cheese_names / number_of_samples\n",
    "    probability_disease_name = number_of_disease_names / number_of_samples \n",
    "    prior_probabilities = [probability_cheese_name , probability_disease_name]\n",
    "    return prior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assigning prior probabilities values of cheese and disease\n",
    "cheese_prior_proba = prior_probabilities(cheese_disease_df_train)[0]\n",
    "disease_prior_proba = prior_probabilities(cheese_disease_df_train)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Bayes model with Laplace smoothing ($\\epsilon=1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using MLE and the previous assumptions we can compute the class-conditional probabilities. Moreover, given the sparsity of our matrix and to avoid to compute log(0), we apply a smoothing process with a Laplace smoothing constant of value 1, to give a small weight to features with a value 0 in our count_vectorize</b>, this yields to the following formula: \n",
    "\n",
    "$$ P(x_i|class_j) = \\frac{count(x_i|y=class_j) + \\epsilon}{{\\sum_{i=1}^{n_{features}} (count(x_i|y=class_j) + n_{features} * \\epsilon}} $$\n",
    "\n",
    "We reason in terms of our previously count_vectorizer matrix, e.g. to get the probability of feature 'bac' given that it belongs to class cheese we compute <b>the frequency of observing 'bac' over all the samples</b> by summing the counts of the rows of our matrix for column j = bac_id. And we divide the previous by <b>the overall counts of all features for a given class, this is done by grouping by class and summing the counts for each column and then adding them to 2 distinct variables corresponding to our respective classes</b>. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_probability_feature_given_class(cheese_disease_df,count_vectorizer,n_features):\n",
    "    number_of_cheese_names = sum(cheese_disease_df[\"class\"]=='1')\n",
    "    number_of_disease_names = sum(cheese_disease_df[\"class\"]=='2')\n",
    "    count_vectorizer\n",
    "    # we add a column with class {1,2} to our array and sort it \n",
    "    # in order to be able to return the sum of all ngrams belonging to the respective classes\n",
    "    # and the total occurences of every ngrams for each class. \n",
    "    for i in range(len(cheese_disease_df)):\n",
    "        if cheese_disease_df.ix[i,1] == '1':\n",
    "            count_vectorizer[i, n_features]  = 1\n",
    "        elif  cheese_disease_df.ix[i,1] == '2':\n",
    "            count_vectorizer[i, n_features]  = 2\n",
    "    count_vectorizer_sorted = count_vectorizer.view(np.ndarray)\n",
    "    count_vectorizer_sorted = count_vectorizer_sorted[np.lexsort((count_vectorizer[:,n_features], ))]\n",
    "    frequency_of_each_trigram_perclass =  np.zeros(shape=(2, n_features ))\n",
    "    \n",
    "    # counting occurences of trigrams per class and total trigrams per class\n",
    "    for j in range(n_features):\n",
    "        frequency_of_each_trigram_perclass[0,j] = (count_vectorizer_sorted[0:number_of_cheese_names-1].sum(axis=0))[j]\n",
    "        frequency_of_each_trigram_perclass[1,j] = (count_vectorizer_sorted[number_of_cheese_names:number_of_disease_names].sum(axis=0))[j]\n",
    "    total_count_of_all_features_in_class_cheese = (frequency_of_each_trigram_perclass).sum(axis=1)[0]\n",
    "    total_count_of_all_features_in_class_disease = (frequency_of_each_trigram_perclass).sum(axis=1)[1]\n",
    "    \n",
    "    # computing the conditional probabilities and filling their values in a (2, n_features) dimension matrix\n",
    "    epsilon = 1\n",
    "    probability_features_given_class = np.zeros(shape=(2, n_features ))\n",
    "    for j in range(n_features):\n",
    "        probability_features_given_class[0, j] = (frequency_of_each_trigram_perclass[0, j] + epsilon) / (total_count_of_all_features_in_class_cheese + n_features * epsilon) \n",
    "        probability_features_given_class[1, j] = (frequency_of_each_trigram_perclass[1, j] + epsilon) / (total_count_of_all_features_in_class_disease + n_features * epsilon) \n",
    "    \n",
    "    return probability_features_given_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we compute the conditional probabilities for the training set using the previous function and return \n",
    "# a (2, n_features) dimension matrix\n",
    "conditional_probabilities_train = compute_probability_feature_given_class(cheese_disease_df_train,count_vectorizer_train,n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best class in <b>NB classification is the most likely</b> or maximum a posteriori ( MAP ) class $$c_{map} = argmax(P(class | features))= argmax(P(class)\\prod_{i=1}^{n_{features}} P(features_i | class)) $$\n",
    "<br>\n",
    "However, <b>the product of the probabilities result in a floating point underflow, so we compute it by adding the logs of the probabilities instead of multiplying the probabilities</b>. Hence: \n",
    "$$c_{map} = argmax(log(P(class))+ \\sum_{i=1}^{n_{features}} log(P(features_i | class))) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict whether a name from a test set belong to a given class, we use the following decision rule: \n",
    "<br>\n",
    "\n",
    "<b>IF P(cheese|featuresFromTest) > P(disease|featuresFromTest) => classify as cheese <br>\n",
    "ELSE classify as disease </b> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_most_likely_class(cheese_disease_df, count_vectorizer,conditional_probabilities, cheese_prior_proba, disease_prior_proba, dict_unique_trigrams):\n",
    "    # we initialize the weights of the class with the log(prior_probabilities) values \n",
    "    # we compute other necessary variables to get the posteriot probabilities\n",
    "    c_cheese = np.log10(cheese_prior_proba)\n",
    "    c_disease = np.log10(disease_prior_proba)\n",
    "    number_of_cheese_names = sum(cheese_disease_df_train[\"class\"]=='1')\n",
    "    number_of_disease_names = sum(cheese_disease_df_train[\"class\"]=='2')\n",
    "    count_vectorizer_sorted = count_vectorizer.view(np.ndarray)\n",
    "    count_vectorizer_sorted = count_vectorizer_sorted[np.lexsort((count_vectorizer[:,n_features], ))]\n",
    "    total_occurences_features_cheese = sum(count_vectorizer_sorted[0:number_of_cheese_names,:-1].sum(axis=1))\n",
    "    total_occurences_features_disease = sum(count_vectorizer_sorted[number_of_cheese_names:,:-1].sum(axis=1))\n",
    "    predictions = []\n",
    "    ids = []\n",
    "    for i in range(len(cheese_disease_df)):\n",
    "        for j in cheese_disease_df.ix[i, 0]:\n",
    "            if j in (dict_unique_trigrams.keys()):\n",
    "                # extract unique_id for every trigram for every row in the names column\n",
    "                ids.append(dict_unique_trigrams.get(j))\n",
    "            else: \n",
    "                c_cheese += np.log10(np.abs(1 / (total_occurences_features_cheese + n_features ) ))\n",
    "                c_disease += np.log10(np.abs(1 / (total_occurences_features_disease + n_features ) ))\n",
    "            \n",
    "        # compute the posterior probabilities P(class | features) using logs \n",
    "        for ido in ids:       \n",
    "            c_cheese += np.log10(np.abs(conditional_probabilities[0,ido]))\n",
    "            c_disease += np.log10(np.abs(conditional_probabilities[1,ido]))\n",
    "        # decision result which result in decision 1 or 2 given the outcome, \n",
    "        # which we then append to a predictions list which is returned\n",
    "        if (c_cheese >= c_disease):\n",
    "            predictions.append(1)\n",
    "        else: \n",
    "            predictions.append(2)\n",
    "        ids = []\n",
    "        c_cheese = np.log10(cheese_prior_proba)\n",
    "        c_disease = np.log10(disease_prior_proba)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we predict the class of each word of the testing set:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_testset = return_most_likely_class(cheese_disease_df_test, count_vectorizer_train,conditional_probabilities_train, cheese_prior_proba, disease_prior_proba, dict_unique_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing accuracy of our model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order, to <b>determine which ngram range returned the highest accuracy </b>for our predictions, we added a ngram parameter in our tokenizer. Morevover, intuitively and by manually scanning the columns of the train file with awk, it appeared that some 3-grams are more likely to happen than 4-grams, returning a count of lines matching 'pain' and 'ain':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Selection_015.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we showed below the precision and accuracy report by setting the ngram parameter to 3, to prove the above statements we ran the calculations of ngrams = 2, 3 and 4 by changing the value of ngram in tokenizer(cheese_disease_df.ix[i,0], ngram) at In [1026] and got the following precisions: \n",
    "<table>\n",
    "    <th>ngram_value</th>\n",
    "    <th>precision</th>\n",
    "     <tr>\n",
    "        <td>2</td>\n",
    "        <td>83.67 %</td>\n",
    "      </tr>\n",
    "       <tr>\n",
    "        <td>3</td>\n",
    "        <td>88.68 %</td>\n",
    "      </tr>\n",
    "    <tr>\n",
    "        <td>4</td>\n",
    "        <td>86.73 %</td>\n",
    "      </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# precision displaying function \n",
    "def precision_is(predictions,actual):\n",
    "    count = 0 \n",
    "    for i in range(len(actual)):\n",
    "        if predictions[i] == int(actual.ix[i,1]):\n",
    "            count += 1\n",
    "    precision = count / len(actual)\n",
    "    print(\"Accuracy: %.2f %%\" % (precision * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.78 %\n",
      "Accuracy in sklearn: 88.78 %\n"
     ]
    }
   ],
   "source": [
    "# we display the result of our manually implemented precision function or using the accuracy_score in sklearn\n",
    "y_actual = list(cheese_disease_df_test.ix[:,1].astype('int'))\n",
    "precision_is(prediction_testset,cheese_disease_df_test)\n",
    "print(\"Accuracy in sklearn: %.2f %%\" % ((metrics.accuracy_score(y_actual,prediction_testset))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     cheese       0.81      0.88      0.85        68\n",
      "    disease       0.93      0.89      0.91       128\n",
      "\n",
      "avg / total       0.89      0.89      0.89       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we display precision, recall and f-score using classification_report function in sklearn.metrics\n",
    "pred_pol_str = [str(i) for i in prediction_testset]\n",
    "predicted_class2 = np.array(pred_pol_str)\n",
    "print(metrics.classification_report(cheese_disease_df_test[\"class\"], predicted_class2,target_names=[\"cheese\",\"disease\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
